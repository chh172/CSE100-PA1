{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "max-cut-in-Pointer&Actor-Critic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1MNZJiEye2+kT1b1QE+cE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chh172/CSE100-PA1/blob/master/max_cut_in_Pointer%26Actor_Critic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from networkx import *\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import keras.backend as K\n",
        "# from keras.engine import InputSpec\n",
        "from tensorflow.keras.layers import InputSpec\n",
        "from keras.activations import tanh, softmax\n",
        "from keras.layers import LSTM\n",
        "\n",
        "# copyright to https://github.com/keon/pointer-networks\n",
        "class Attention(keras.layers.Layer):\n",
        "    \"\"\"\n",
        "        Attention layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dimensions, name='attention'):\n",
        "        super(Attention, self).__init__(name=name, trainable=True)\n",
        "        self.W1 = keras.layers.Dense(hidden_dimensions, use_bias=False)\n",
        "        self.W2 = keras.layers.Dense(hidden_dimensions, use_bias=False)\n",
        "        self.V = keras.layers.Dense(1, use_bias=False)\n",
        "\n",
        "    def call(self, encoder_outputs, dec_output, mask=None):\n",
        "\n",
        "        w1_e = self.W1(encoder_outputs)\n",
        "        w2_d = self.W2(dec_output)\n",
        "        tanh_output = tanh(w1_e + w2_d)\n",
        "        v_dot_tanh = self.V(tanh_output)\n",
        "        print(v_dot_tanh.shape)\n",
        "        if mask is not None:\n",
        "            v_dot_tanh += (mask * -1e9)\n",
        "        attention_weights = softmax(v_dot_tanh, axis=1)\n",
        "        att_shape = K.shape(attention_weights)\n",
        "        return K.reshape(attention_weights, (att_shape[0], att_shape[1]))\n",
        "\n",
        "\n",
        "class Decoder(keras.layers.Layer):\n",
        "    \"\"\"\n",
        "        Decoder class for PointerLayer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dimensions):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.lstm = keras.layers.LSTM(\n",
        "            hidden_dimensions, return_sequences=False, return_state=True)\n",
        "\n",
        "    def call(self, x, hidden_states):\n",
        "        dec_output, state_h, state_c = self.lstm(\n",
        "            x, initial_state=hidden_states)\n",
        "        return dec_output, [state_h, state_c]\n",
        "\n",
        "    def get_initial_state(self, inputs):\n",
        "        return self.lstm.get_initial_state(inputs)\n",
        "\n",
        "    def process_inputs(self, x_input, initial_states, constants):\n",
        "        return self.lstm._process_inputs(x_input, initial_states, constants)\n",
        "\n",
        "\n",
        "class PointerLSTM(keras.layers.Layer):\n",
        "    \"\"\"\n",
        "        PointerLSTM\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dimensions, name='pointer', **kwargs):\n",
        "        super(PointerLSTM, self).__init__(**kwargs)\n",
        "        self.hidden_dimensions = hidden_dimensions\n",
        "        self.attention = Attention(hidden_dimensions)\n",
        "        self.decoder = Decoder(hidden_dimensions)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(PointerLSTM, self).build(input_shape)\n",
        "        self.input_spec = [InputSpec(shape=input_shape)]\n",
        "\n",
        "    def call(self, x, training=None, mask=None, states=None):\n",
        "        \"\"\"\n",
        "        :param Tensor x: Should be the output of the decoder\n",
        "        :param Tensor states: last state of the decoder\n",
        "        :param Tensor mask: The mask to apply\n",
        "        :return: Pointers probabilities\n",
        "        \"\"\"\n",
        "\n",
        "        input_shape = self.input_spec[0].shape\n",
        "        en_seq = x\n",
        "        x_input = x[:, input_shape[1] - 1, :]\n",
        "        x_input = K.repeat(x_input, input_shape[1])\n",
        "        if states:\n",
        "            initial_states = states\n",
        "        else:\n",
        "            initial_states = self.decoder.get_initial_state(x_input)\n",
        "\n",
        "        constants = []\n",
        "        preprocessed_input, _, constants = self.decoder.process_inputs(\n",
        "            x_input, initial_states, constants)\n",
        "        constants.append(en_seq)\n",
        "        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n",
        "                                             initial_states,\n",
        "                                             go_backwards=self.decoder.lstm.go_backwards,\n",
        "                                             constants=constants,\n",
        "                                             input_length=input_shape[1])\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def step(self, x_input, states):\n",
        "        x_input = K.expand_dims(x_input,1)\n",
        "        input_shape = self.input_spec[0].shape\n",
        "        en_seq = states[-1]\n",
        "        _, [h, c] = self.decoder(x_input, states[:-1])\n",
        "        dec_seq = K.repeat(h, input_shape[1])\n",
        "        probs = self.attention(dec_seq, en_seq)\n",
        "        return probs, [h, c]\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        # output shape is not affected by the attention component\n",
        "        return (input_shape[0], input_shape[1], input_shape[1])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[1], input_shape[1])"
      ],
      "metadata": {
        "id": "FbGFhCwjtHY9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n",
        "from networkx import *\n",
        "n = 6\n",
        "p = 0.5\n",
        "g = erdos_renyi_graph(n, p)\n",
        "print(g. nodes)\n",
        "# [0, 1, 2, 3, 4, 5] \n",
        "print(g. edges)\n",
        "# [(0, 1), (0, 2), (0, 4), (1, 2), (1, 5), (3, 4), (4, 5)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f-O7ecEb4Aj",
        "outputId": "1b27d1f6-4d16-45eb-eb79-b753ad5b694d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5]\n",
            "[(0, 1), (0, 2), (0, 4), (0, 5), (1, 3), (1, 4), (1, 5), (2, 5), (3, 4), (3, 5), (4, 5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Description: this function randomly generate a sequence of graphs G(V,E)\n",
        "# where graphs are represented by their adjacency matrix A\n",
        "# and the distribution of V and E are all uniform.\n",
        "# It takes in 'number' of graphs, 'infimum' and 'supremum' of |V|. \n",
        "import numpy as np\n",
        "from networkx import *\n",
        "import random\n",
        "def graph_seq_generator(num, inf, sup):\n",
        "  atlas = []\n",
        "  for i in range(num):\n",
        "    A = adjacency_matrix(erdos_renyi_graph(np.random.randint(inf,sup), 0.5))\n",
        "    #print(A.todense())\n",
        "    atlas.append(A.todense())\n",
        "  return atlas    \n",
        "\n"
      ],
      "metadata": {
        "id": "HXAwLP_Hh6S3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Description: this function tensor-ize the atlas, preparing for LSTM\n",
        "def input_generator(atlas):\n",
        "  return tf.cast(np.array(random.sample(atlas,1)),tf.float32)"
      ],
      "metadata": {
        "id": "9zlJq0DRyAez"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Description: this function randomly generate a random graph G(V,E)\n",
        "# where graph is represented by their adjacency matrix A\n",
        "\n",
        "def graph_generator(vertices):\n",
        "  return tf.cast(np.array([adjacency_matrix(erdos_renyi_graph(vertices, 0.5)).todense()]),tf.float32)\n"
      ],
      "metadata": {
        "id": "lfxkb4KMs52M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit testing\n",
        "# atlas = graph_seq_generator(4,1,5)\n",
        "#print(atlas[1])\n",
        "#inp = Input(atlas[1])\n",
        "#print(inp)\n",
        "#for i in range(3):\n",
        "  #print(g[i].nodes)\n",
        "  #\n",
        "  #print(g[i].edges)\n",
        "  #\n",
        "  #print(len(g[i].nodes))\n",
        "#g = random.sample(atlas,2)\n",
        "#print(g[1])\n",
        "#input = input_generator(atlas)\n",
        "#input_2 = tf.cast(np.array([atlas[1]]),tf.float32)\n",
        "#print(input)\n",
        "#print(input_2)\n",
        "#print(input.shape[0])\n",
        "#print(input.shape[1])\n",
        "#print(input.shape[2])\n",
        "#print(input.shape)\n",
        "#print(input.shape)\n",
        "# x = Input(shape=(32,))\n",
        "#x_1 = Input(input)\n",
        "# print(x)\n",
        "# print(graph_generator(5))\n",
        "# print(tf.keras.Input(shape=(10,None,5),tensor=graph_generator(5)))\n",
        "def increment(x):\n",
        "  x = x +1\n",
        "  return\n",
        "x = 1\n",
        "increment(x)\n",
        "print(x)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-bmxoRsJmcc",
        "outputId": "a2676ba3-7fb1-48ea-860a-6f8121a15221"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# actor-critic training\n",
        "# starting state: (0,0,...,0)\n",
        "# action space = {action: flip a single bit in state} U {ternimate}\n",
        "def actor_critic_algo(actor,critic,graph):\n",
        "  # randomly init 'phi', 'theta'\n",
        "  # do until theta converges\n",
        "    # init starting state\n",
        "    # \\lambda = 1\n",
        "    # do until reach terminal state\n",
        "      # In state 's', select action 'a' given by actor\n",
        "      # perform 'a' and collect reward r and new state (terminal state)\n",
        "      # update delta\n",
        "      # update value function parameter 'phi'\n",
        "      # update policy parameter 'theta'\n",
        "      # update discount \n",
        "      # update state\n",
        "  return\n",
        "\n",
        "def delta_update(critic,reward):\n",
        "  return \n",
        "\n",
        "def value_f_update(critic, delta ,phi, beta):\n",
        "  return phi+ beta*delta*value_grad(critic,phi)\n",
        "\n",
        "def policy_update(actor,alpha,lamb,delta,theta):\n",
        "  return theta + alpha*lamb*delta*policy_grad(actor,theta)\n",
        "#  \n",
        "def policy_grad(actor,theta):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(theta)\n",
        "    y = tf.math.log(actor(theta))\n",
        "  return tape.gradient(y,theta) \n",
        "def value_grad(critic,phi):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(phi)\n",
        "    y = critic(phi)\n",
        "  return tape.gradient(y, phi) "
      ],
      "metadata": {
        "id": "UuBJub5Wd6dR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# training main in way 2\n",
        "\n",
        "hidden_size = 128\n",
        "vertices_size = 5\n",
        "\n",
        "# input is a [A], where A is the adjacency matrix, which is a square matrix\n",
        "# sequence length shall match the number of rows and feature_dim is number of cols\n",
        "# note the feature for each node is its adjacency relation (row vector in adjacency matrix)\n",
        "seq_len = vertices_size\n",
        "feature_dim = vertices_size\n",
        "\n",
        "encoder = LSTM(hidden_size,return_sequences = True, name=\"encoder\",return_state=True)\n",
        "actor_decoder = PointerLSTM( hidden_size, name=\"actor_decoder\")\n",
        "critic_decoder = LSTM(hidden_size,name=\"critic_decoder\")\n",
        "\n",
        "inputs = keras.layers.Input(shape=(seq_len, feature_dim)) \n",
        "encoder_o, state_h, state_c = encoder(inputs)\n",
        "policy = actor_decoder(encoder_o,states=[state_h, state_c])\n",
        "scores = critic_decoder(encoder_o)\n",
        "\n",
        "\n",
        "\n",
        "#actor = tf.keras.Model(inputs=inputs, outputs=policy)\n",
        "\n",
        "#critic = tf.keras.Model(inputs=inputs, outputs=scores)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=[policy,scores])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss=tf.keras.losses.Huber(),\n",
        "              metrics=['accuracy'])\n",
        "graph = graph_generator(5)\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(graph)\n",
        "  y_p, y_c= model(graph)\n",
        "\n",
        "grad = tape.gradient(y_p,graph)\n",
        "print(grad)\n",
        "# for i in range(5):\n",
        "graph = graph_generator(5)\n",
        "print(graph)\n",
        "encoder_outputs, state_h, state_c = encoder(graph)\n",
        "#print(encoder_outputs)\n",
        "print(\"hello world\")\n",
        "policy = actor_decoder(encoder_outputs)\n",
        "print(policy)\n",
        "scores = critic_decoder(encoder_outputs)\n",
        "print(\"hello world\")\n",
        "print(scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEWMHPkVeFnT",
        "outputId": "e493e3ca-3083-4208-d3c7-ac4599f4e504"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 5, 1)\n",
            "(None, 5, 1)\n",
            "(1, 5, 1)\n",
            "(1, 5, 1)\n",
            "(1, 5, 1)\n",
            "(1, 5, 1)\n",
            "(1, 5, 1)\n",
            "(1, 5, 1)\n",
            "tf.Tensor(\n",
            "[[[ 6.0458760e-10 -7.5285472e-11  4.8421123e-10 -1.1959041e-10\n",
            "   -4.2477780e-10]\n",
            "  [ 7.6868217e-10 -1.2971360e-10  4.7492005e-10 -2.0694016e-10\n",
            "   -5.2709648e-10]\n",
            "  [ 9.6264707e-10 -2.6364563e-10  6.0354527e-10 -2.3108065e-10\n",
            "   -6.8260475e-10]\n",
            "  [ 1.2969970e-09 -4.3170742e-10  5.7867711e-10 -3.6762932e-10\n",
            "   -8.2845975e-10]\n",
            "  [ 1.5167826e-09 -3.5578995e-10  6.1202021e-10 -6.7534517e-10\n",
            "   -9.7888719e-10]]], shape=(1, 5, 5), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0. 0. 1. 1. 1.]\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [1. 0. 0. 0. 1.]\n",
            "  [1. 1. 0. 0. 0.]\n",
            "  [1. 0. 1. 0. 0.]]], shape=(1, 5, 5), dtype=float32)\n",
            "hello world\n",
            "(1, 5, 1)\n",
            "(1, 5, 1)\n",
            "(1, 5, 1)\n",
            "(1, 5, 1)\n",
            "(1, 5, 1)\n",
            "(1, 5, 1)\n",
            "tf.Tensor(\n",
            "[[[0.19770537 0.19880718 0.20375657 0.20056958 0.19916134]\n",
            "  [0.19770473 0.19880463 0.20375726 0.20057082 0.19916257]\n",
            "  [0.19770396 0.19880229 0.20375772 0.20057203 0.19916405]\n",
            "  [0.19770327 0.19880036 0.20375797 0.200573   0.19916546]\n",
            "  [0.19770272 0.19879882 0.20375806 0.20057368 0.19916667]]], shape=(1, 5, 5), dtype=float32)\n",
            "hello world\n",
            "tf.Tensor(\n",
            "[[ 1.0248367e-02 -9.0065884e-04  1.4699780e-02  2.3361774e-02\n",
            "  -1.2918411e-02 -6.1765830e-03 -6.8962676e-03 -4.4236358e-02\n",
            "   2.6996460e-02 -5.1029427e-03 -7.8048324e-03  1.1124838e-02\n",
            "  -2.2441449e-02  1.6175747e-02  1.9129256e-02 -3.2925777e-02\n",
            "  -3.1302150e-03  3.9233040e-02  2.4070069e-02 -8.4443745e-04\n",
            "   2.2648079e-03 -1.0928877e-02  3.5332933e-03  2.4576295e-02\n",
            "   1.9448690e-02 -8.2236156e-03 -2.3653941e-02 -2.7987648e-02\n",
            "  -2.6317487e-02  2.4188409e-02 -7.7430223e-04 -1.5301061e-02\n",
            "   2.1979935e-03 -3.3390161e-02 -1.8618742e-02 -3.8692050e-03\n",
            "  -8.9740409e-03  3.7842296e-02  1.0471633e-03  2.0948062e-02\n",
            "  -8.8771293e-03 -3.0914804e-03  3.6980228e-03  6.0721184e-03\n",
            "  -1.6494282e-02 -1.9730875e-02  2.4001673e-02  7.8228088e-03\n",
            "   1.9899542e-02 -4.9039368e-03 -1.1560541e-02 -1.3763100e-02\n",
            "   3.1717536e-03 -1.0798104e-02  2.0428568e-02  3.0200034e-03\n",
            "  -4.8930659e-03  1.7104618e-02 -3.9408751e-02 -9.5759742e-03\n",
            "  -7.8561446e-03 -2.2972424e-02 -3.0437818e-02 -2.2520283e-02\n",
            "   1.1863552e-02 -3.0292518e-02  9.3597313e-04 -1.2486332e-02\n",
            "   2.3263402e-02  1.1717417e-02 -1.0559700e-03 -9.9374177e-03\n",
            "  -1.4795758e-02  2.2792727e-02 -8.7314853e-03 -3.7254461e-03\n",
            "  -1.0741659e-02  3.5133760e-02 -1.6567791e-02  1.6466027e-02\n",
            "   5.4884870e-03  9.3520228e-03  1.2785747e-03  7.7500935e-03\n",
            "   1.5519995e-02  3.1929282e-03 -1.2018605e-02  5.1563278e-02\n",
            "  -2.9107062e-02  3.7580010e-02  1.5554582e-02 -1.8789308e-02\n",
            "  -2.3647169e-02 -1.3514356e-02  1.0042304e-02  8.4911473e-03\n",
            "   4.8138495e-04 -3.8480081e-03 -6.0824789e-03  1.2168544e-02\n",
            "   4.1629672e-03  1.4024089e-02 -1.7034076e-03 -6.7154700e-03\n",
            "   1.7130900e-02  3.0093238e-02  3.5583906e-02  1.4716375e-03\n",
            "  -1.2565075e-03 -5.4714284e-03  2.9321130e-02  6.1612129e-03\n",
            "  -1.2557441e-03  8.9778630e-03  6.0875383e-03  1.2044386e-03\n",
            "  -4.8119365e-03 -2.1392496e-02  7.4026911e-03  2.3270808e-02\n",
            "  -1.0658537e-02  1.1060113e-02 -1.9527627e-02  2.0041633e-05\n",
            "   1.7810851e-02  1.9887006e-02  1.5460096e-02 -4.2934958e-03]], shape=(1, 128), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XViDljAey-BG",
        "outputId": "64e2d947-a686-4b23-a9ea-800f0dc83e86"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# training main in way 1\n",
        "\n",
        "actor_encoder = tf.keras.layers.LSTM(128, return_sequences=True, return_state=True)\n",
        "# pointer works as decoder\n",
        "pointer = tf.keras.layers.LSTM(128, return_sequences=True, return_state=True)\n",
        "# critic/value works as encoder\n",
        "critic = tf.keras.layers.LSTM(128, return_sequences=True, return_state=True)\n",
        "inputs = tf.keras.Input(shape=(None,5)) # vertices size 5\n",
        "encoder_outputs, state_h, state_c = actor_encoder(inputs)\n",
        "decoder_outputs, de_state_h, de_state_c = pointer(encoder_outputs)\n",
        "# TODO: ADD SOFTMAX as classifier, then feed to critic\n",
        "value, critic_state_h, critic_state_c = critic(decoder_outputs)\n",
        "actor = tf.keras.Model(inputs=inputs, outputs=decoder_outputs)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=value)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss=tf.keras.losses.Huber(),\n",
        "              metrics=['accuracy'])\n",
        "graph = graph_generator(5)\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(graph)\n",
        "  y = model(graph)\n",
        "\n",
        "grad = tape.gradient(y,graph)\n",
        "print(grad)\n",
        "# TODO: Specify the functioning of pointer network (in detail)\n",
        "# train it such that pointer returns \"sequence\" of indices from largest probability to lowest\n",
        "\n",
        "for i in range(5):\n",
        "  graph = graph_generator(5)\n",
        "  #print(graph)\n",
        "  actor_outputs, state_h, state_c = actor_encoder(graph)\n",
        "  decoder_outputs, de_state_h, de_state_c = pointer(actor_outputs)\n",
        "  value, critic_state_h, critic_state_c = critic(decoder_outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk4gQ46_4nDA",
        "outputId": "63102af0-7b82-4566-e9f0-d5a5548eadb1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[-1.9091982e-03  6.2075101e-02 -1.0138596e-01  8.7714098e-02\n",
            "    3.4673616e-02]\n",
            "  [ 3.0340068e-03  4.3968163e-02 -6.6788293e-02  6.0502719e-02\n",
            "    2.0162243e-02]\n",
            "  [ 1.8023690e-03  2.8962709e-02 -3.7919164e-02  3.0463574e-02\n",
            "    1.4514055e-02]\n",
            "  [ 6.7431107e-04  1.8162895e-02 -1.5985496e-02  1.3181592e-02\n",
            "    1.0792833e-02]\n",
            "  [ 1.0046002e-04  5.1129898e-03 -4.4046668e-03  3.7885746e-03\n",
            "    2.9451679e-03]]], shape=(1, 5, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xS3vSI4TEIqX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (inference template) main\n",
        "\n",
        "#atlas = graph_seq_generator(1,1,5)\n",
        "graph = graph_generator(5)\n",
        "#print(graph)\n",
        "# actor/policy works as encoder\n",
        "actor = tf.keras.layers.LSTM(8, return_sequences=True, return_state=True)\n",
        "# pointer works as decoder\n",
        "pointer = tf.keras.layers.LSTM(8, return_sequences=True, return_state=True)\n",
        "# critic/value works as encoder\n",
        "critic = tf.keras.layers.LSTM(8, return_sequences=True, return_state=True)\n",
        "actor_outputs, state_h, state_c = actor(graph)\n",
        "decoder_outputs, de_state_h, de_state_c = pointer(actor_outputs)\n",
        "value, critic_state_h, critic_state_c = critic(decoder_outputs)\n",
        "#print(value)\n",
        "#print(actor_outputs)\n",
        "print(decoder_outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBYsGYKkscVI",
        "outputId": "273cb4db-106c-4f2e-bf78-faa57c676495"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0.00545292  0.00019841  0.00227465  0.00554217 -0.01269028\n",
            "   -0.00623421  0.01094057  0.00446605]\n",
            "  [ 0.00964246  0.00209888  0.00357724  0.00762778 -0.01860836\n",
            "   -0.0099867   0.01560443  0.00614076]\n",
            "  [ 0.02958955  0.01480201 -0.00704743  0.0066876  -0.03216184\n",
            "   -0.01166113  0.01171903 -0.01194777]\n",
            "  [ 0.03616894  0.00810451 -0.01115538 -0.00103414 -0.04054455\n",
            "   -0.01983783 -0.01930784 -0.02853147]\n",
            "  [ 0.05480311  0.01469139 -0.02617485 -0.00451238 -0.04847791\n",
            "   -0.02508336 -0.03667019 -0.0415091 ]]], shape=(1, 5, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CGlxycKIJFu_"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}